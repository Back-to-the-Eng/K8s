apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-kafka-consumer
  namespace: default
spec:
  type: Python
  mode: cluster
  sparkVersion: "3.5.1"

  image: "apache/spark:3.5.1-scala2.12-java11-python3-ubuntu"
  imagePullPolicy: Always

  mainApplicationFile: "local:///opt/spark/code/user_activity_streaming.py"

  sparkConf:
    "spark.kubernetes.container.image.pullPolicy": "Always"
    "spark.jars.packages": "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1"
    "spark.jars.ivy": "/tmp/.ivy2"
    "spark.driver.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp -Divy.default.ivy.user.dir=/tmp"
    "spark.executor.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp -Divy.default.ivy.user.dir=/tmp"

  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 3
    onSubmissionFailureRetryInterval: 10

  driver:
    cores: 1
    memory: "1g"
    serviceAccount: spark
    labels:
      version: "3.5.1"
    volumeMounts:
    - name: spark-code
      mountPath: /opt/spark/code
    env:
      - name: KAFKA_BOOTSTRAP_SERVERS
        value: "streaming-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092"

  executor:
    cores: 1
    memory: "2g"
    instances: 2
    labels:
      version: "3.5.1"
    volumeMounts:
    - name: spark-code
      mountPath: /opt/spark/code
    env:
      - name: KAFKA_BOOTSTRAP_SERVERS
        value: "streaming-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092"

  volumes:
  - name: spark-code
    configMap:
      name: spark-app-code
