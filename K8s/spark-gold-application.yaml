apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-gold-cluster
  namespace: default
spec:
  type: Python
  mode: cluster  # Cluster Mode
  sparkVersion: "3.5.1"
  
  image: apache/spark:3.5.1-scala2.12-java11-python3-ubuntu
  imagePullPolicy: IfNotPresent
  
  # 코드는 ConfigMap에서 가져옴
  mainApplicationFile: "local:///opt/spark/code/clickhouse_gold.py"
  
  # Spark 설정
  sparkConf:
    "spark.kubernetes.container.image.pullPolicy": "IfNotPresent"
    "spark.driver.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp"
    "spark.executor.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp"
    "spark.jars.packages": "org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,com.clickhouse.spark:clickhouse-spark-runtime-3.5_2.12:0.9.0,com.clickhouse:clickhouse-jdbc:0.9.4"
    "spark.hadoop.fs.s3a.endpoint": "http://minio.storage.svc.cluster.local:9000"
    "spark.hadoop.fs.s3a.access.key": "admin"
    "spark.hadoop.fs.s3a.secret.key": "password1234"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.sql.catalog.clickhouse": "com.clickhouse.spark.ClickHouseCatalog"
    "spark.sql.catalog.clickhouse.host": "clickhouse.storage.svc.cluster.local"
    "spark.sql.catalog.clickhouse.protocol": "http"
    "spark.sql.catalog.clickhouse.http_port": "8123"
    "spark.sql.catalog.clickhouse.user": "default"
    "spark.sql.catalog.clickhouse.password": "backtoeng"
    "spark.sql.catalog.clickhouse.database": "logs"
    "spark.driver.memory": "2g"
    "spark.executor.memory": "4g"
  
  # 재시작 정책
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 3
    onSubmissionFailureRetryInterval: 10
  
  # Driver 설정
  driver:
    cores: 1
    memory: "2g"
    serviceAccount: spark
    initContainers:
    - name: init-ivy-cache
      image: busybox:1.36
      command: ["sh", "-c", "mkdir -p /tmp/.ivy2/cache /tmp/.ivy2/jars && chmod -R 777 /tmp/.ivy2"]
    env:
    - name: MINIO_ENDPOINT
      value: "http://minio.storage.svc.cluster.local:9000"
    - name: MINIO_ACCESS_KEY
      value: "admin"
    - name: MINIO_SECRET_KEY
      value: "password1234"
    - name: CLICKHOUSE_HOST
      value: "clickhouse.storage.svc.cluster.local"
    - name: CLICKHOUSE_PROTOCOL
      value: "http"
    - name: CLICKHOUSE_HTTP_PORT
      value: "8123"
    - name: CLICKHOUSE_DB
      value: "logs"
    - name: CLICKHOUSE_USER
      value: "default"
    - name: CLICKHOUSE_PASSWORD
      value: "backtoeng"
    - name: SCALA_BINARY_VERSION
      value: "2.12"
    - name: CLICKHOUSE_SPARK_CONNECTOR_VERSION
      value: "0.9.0"
    - name: CLICKHOUSE_JDBC_VERSION
      value: "0.9.4"
    volumeMounts:
    - name: spark-gold-code
      mountPath: /opt/spark/code
    - name: checkpoint-storage
      mountPath: /app/checkpoints  # PVC 마운트 (체크포인트 영구 저장)
  
  # Executor 설정 (분산 처리)
  executor:
    cores: 2
    memory: "4g"
    instances: 3  # Executor 3개로 분산 처리
    env:
    - name: MINIO_ENDPOINT
      value: "http://minio.storage.svc.cluster.local:9000"
    - name: MINIO_ACCESS_KEY
      value: "admin"
    - name: MINIO_SECRET_KEY
      value: "password1234"
    - name: CLICKHOUSE_HOST
      value: "clickhouse.storage.svc.cluster.local"
    - name: CLICKHOUSE_PROTOCOL
      value: "http"
    - name: CLICKHOUSE_HTTP_PORT
      value: "8123"
    - name: CLICKHOUSE_DB
      value: "logs"
    - name: CLICKHOUSE_USER
      value: "default"
    - name: CLICKHOUSE_PASSWORD
      value: "backtoeng"
    volumeMounts:
    - name: spark-gold-code
      mountPath: /opt/spark/code
    # Executor는 체크포인트에 직접 접근하지 않음 (Driver만 관리)
  
  # Volumes 정의 (spec 레벨)
  volumes:
  - name: spark-gold-code
    configMap:
      name: spark-gold-code
  - name: checkpoint-storage
    persistentVolumeClaim:
      claimName: spark-gold-checkpoint-pvc  # 기존 PVC 사용
